# ARC-IT: Rule-Conditioned Transformer Configuration
# Auto-adapts to Mac (dev) vs H100/A100 (training) based on device detection

# ─── Data ───────────────────────────────────────────────────────────
data:
  arc_agi1_path: "References/ARC-AGI"
  arc_agi2_path: "References/ARC-AGI-2"
  re_arc_path: "References/RE-ARC"       # michaelhodel/re-arc (400 tasks × 1000 examples)
  canvas_size: 64                # Fixed canvas for all grids (VARC-proven)
  num_colors: 12                 # 10 ARC + IGNORE + PAD
  max_grid_size: 30              # Max raw grid dimension
  max_demos: 5                   # Max demonstration pairs per task
  re_arc_samples_per_task: 25    # Samples generated per RE-ARC task (random K+1 selection)
  repeat_factor: 1               # Use natural epochs with on-the-fly augmentation

  augmentation:
    geometric: true              # 8 variants (rotations + flips + transpose)
    color_permutation: true      # Random color remapping
    num_color_perms: 10          # Color permutations per geometric variant
    keep_background: true        # Keep color 0 (black) fixed during permutation
    resolution_scaling: true     # Random upscale within canvas
    translation: true            # Random position offset in canvas

# ─── Model ──────────────────────────────────────────────────────────
model:
  hidden_size: 384               # Shared hidden dimension (~20M total params)
  mlp_ratio: 2.5                 # FFN expansion ratio

  # Grid Tokenizer (shared for all grids)
  tokenizer:
    patch_size: 4                # 64/4 = 16x16 patches = 256 tokens per grid

  # Rule Encoder — extracts transformation rule from demo pairs
  rule_encoder:
    pair_layers: 2               # Per-pair cross-attention layers
    agg_layers: 2                # Cross-pair aggregation layers
    num_heads: 8                 # Attention heads (384/8 = 48 dim/head)
    num_rule_tokens: 64          # Fixed-length rule representation

  # Rule Applier — applies rule to test input
  rule_applier:
    num_layers: 4                # Transformer decoder layers
    num_heads: 8                 # Attention heads

  # Spatial Decoder (tokens → 64x64 grid logits)
  decoder:
    upsample_method: "transposed_conv"
    hidden_channels: [192, 96]   # Matched to hidden_size=384

# ─── Training ───────────────────────────────────────────────────────
training:
  # Auto-scaled by device (these are A100/H100 defaults)
  batch_size: 32                 # Mac override: 4 (task-level = more memory per sample)
  num_workers: 8                 # Mac override: 0
  gradient_clip: 1.0

  # Three-stage schedule with per-stage data sources
  stage1:
    name: "pretrain"
    data_sources: ["re_arc", "agi1"]  # RE-ARC + AGI-1 only (no AGI-2)
    epochs: 30                   # Bulk pretraining on large synthetic data
    lr: 3.0e-4

  stage2:
    name: "finetune"
    data_sources: ["agi1", "agi2"]    # Fine-tune on real ARC tasks
    epochs: 20
    lr: 1.0e-4

  stage3:
    name: "hard_focus"
    data_sources: ["agi1", "agi2"]    # Hard focus with AGI-2 oversampling
    epochs: 10
    lr: 3.0e-5
    agi2_oversample: 2.0         # 2x weight on AGI-2 tasks

  optimizer:
    name: "adamw"
    weight_decay: 0.01
    betas: [0.9, 0.999]

  scheduler:
    name: "cosine"
    warmup_ratio: 0.1

  # Logging & Checkpointing
  log_every_n_steps: 100
  save_every_n_epochs: 10
  checkpoint_dir: "checkpoints"

# ─── Test-Time Training ─────────────────────────────────────────────
ttt:
  enabled: true
  steps: 100                     # Fine-tuning steps per task
  lr: 1.0e-4
  batch_size: 8                  # Mac: 2
  num_candidates: 32             # Augmentation-based candidate generation

# ─── Evaluation ─────────────────────────────────────────────────────
evaluation:
  val_split_ratio: 0.1
  val_data_sources: ["agi1", "agi2"]  # Always validate on real ARC
  metrics: ["pixel_accuracy", "grid_exact_match"]
  visualize_every_n_tasks: 50
