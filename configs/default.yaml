# ARC-IT Default Configuration
# Auto-adapts to Mac (dev) vs H100 (training) based on device detection

# ─── Data ───────────────────────────────────────────────────────────
data:
  arc_agi1_path: "References/ARC-AGI"
  arc_agi2_path: "References/ARC-AGI-2"
  canvas_size: 64                # Fixed canvas for all grids (VARC-proven)
  num_colors: 12                 # 10 ARC + IGNORE + PAD
  max_grid_size: 30              # Max raw grid dimension
  repeat_factor: 1               # Use natural epochs with on-the-fly augmentation (VARC-style)

  augmentation:
    geometric: true              # 8 variants (rotations + flips + transpose)
    color_permutation: true      # Random color remapping
    num_color_perms: 10          # Color permutations per geometric variant
    keep_background: true        # Keep color 0 (black) fixed during permutation
    resolution_scaling: true     # Random upscale within canvas
    translation: true            # Random position offset in canvas

# ─── Model ──────────────────────────────────────────────────────────
model:
  # DINOv2 Encoder (FROZEN) — strong discriminative features for visual patterns
  encoder:
    name: "dinov2_vitl14"        # DINOv2 ViT-L/14 pretrained
    pretrained: true
    frozen: true
    input_size: 224              # ViT expects 224x224
    embed_dim: 1024              # DINOv2 ViT-L output dimension
    num_patches: 256             # (224/14)^2

  # Bridge Module (TRAINABLE)
  bridge:
    hidden_dim: 2048             # Intermediate expansion
    output_dim: 1152             # Must match Sana hidden_size
    dropout: 0.1
    use_2d_pos_embed: true       # Learnable 16x16 positional embeddings

  # Sana Transformer Backbone (TRAINABLE)
  sana:
    hidden_size: 1152            # Sana-0.6B native size
    depth: 28                    # Number of transformer blocks
    num_heads: 16                # Attention heads
    linear_head_dim: 32          # For linear attention (LiteLA)
    mlp_ratio: 2.5               # FFN expansion ratio
    attn_type: "linear"          # linear | flash
    ffn_type: "glumbconv"        # glumbconv | mlp
    pretrained: false            # Train Sana from random init (pretrained was text-to-image, hurts ARC)

  # Spatial Decoder (TRAINABLE)
  decoder:
    upsample_method: "transposed_conv"  # transposed_conv | interpolate
    hidden_channels: [512, 256]         # Channel sizes for upsampling layers

# ─── Training ───────────────────────────────────────────────────────
training:
  # Auto-scaled by device (these are A100/H100 defaults)
  batch_size: 64                 # Mac override: 4
  num_workers: 8                 # Mac override: 0
  epochs: 70                     # Total across all stages
  gradient_clip: 1.0
  gradient_checkpointing: true   # Mac: false (not needed)

  # Three-stage schedule
  stage1:
    name: "bridge_alignment"
    epochs: 10
    lr: 2.0e-4                   # Higher LR for fresh bridge weights
    freeze_sana: true

  stage2:
    name: "full_training"
    epochs: 50                   # Much longer to converge (VARC uses 100 total)
    lr: 1.0e-4                   # Higher initial LR, cosine will decay
    freeze_sana: false

  stage3:
    name: "hard_focus"
    epochs: 10
    lr: 1.0e-5
    freeze_sana: false
    agi2_oversample: 2.0         # 2x weight on AGI-2 tasks

  optimizer:
    name: "adamw"
    weight_decay: 0.01
    betas: [0.9, 0.999]

  scheduler:
    name: "cosine"
    warmup_ratio: 0.1

  # Logging & Checkpointing
  log_every_n_steps: 100
  save_every_n_epochs: 10        # Save periodic checkpoints every 10 epochs
  checkpoint_dir: "checkpoints"

# ─── Test-Time Training ─────────────────────────────────────────────
ttt:
  enabled: true
  steps: 100                     # Fine-tuning steps per task
  lr: 1.0e-4
  batch_size: 8                  # Mac: 2
  num_layers_to_update: 4        # Last N Sana layers
  num_candidates: 32             # Multi-sample generation
  num_denoising_steps: 50        # Per candidate

# ─── Evaluation ─────────────────────────────────────────────────────
evaluation:
  val_split_ratio: 0.1           # Hold out 10% for validation
  metrics: ["pixel_accuracy", "grid_exact_match"]
  visualize_every_n_tasks: 50
